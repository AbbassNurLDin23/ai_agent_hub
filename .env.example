# =========================
# Backend Configuration
# =========================
PORT=4000
NODE_ENV=production

# PostgreSQL connection string
# postgresql://USER:PASSWORD@HOST:PORT/DB_NAME?schema=public
DATABASE_URL=postgresql://postgres:password@localhost:5432/ai_agent?schema=public

# Allowed frontend origin (CORS)
CLIENT_ORIGIN=http://localhost:8080


# =========================
# Provider API Keys (Backend Only)
# Leave EMPTY if you do not have a key
# If a key is empty, that provider is disabled automatically
# =========================
OPENAI_API_KEY=
GOOGLE_API_KEY=
GROQ_API_KEY=


# =========================
# Frontend Configuration (Vite)
# =========================
VITE_PORT=8080

# Backend base URL used by the frontend
VITE_API_URL=http://localhost:4000


# =========================
# Providers + Models Configuration (Backend reads this)
# - enabled: controls whether provider is allowed
# - models: list of allowed models for that provider
# - Model "id" must match the actual API model id
# =========================
PROVIDERS_JSON='[{"provider":"google","enabled":true,"models":[{"id":"gemini-2.5-flash","name":"Gemini 2.5 Flash","description":"Fast and balanced, great for most tasks"},{"id":"gemini-2.5-pro","name":"Gemini 2.5 Pro","description":"Top-tier reasoning and multimodal"},{"id":"gemini-2.5-flash-lite","name":"Gemini 2.5 Flash Lite","description":"Fastest and cheapest option"}]},{"provider":"openai","enabled":true,"models":[{"id":"gpt-5","name":"GPT-5","description":"Powerful all-rounder, best accuracy"},{"id":"gpt-5-mini","name":"GPT-5 Mini","description":"Lower cost with strong performance"},{"id":"gpt-5-nano","name":"GPT-5 Nano","description":"Speed optimized, high volume"}]},{"provider":"groq","enabled":true,"models":[{"id":"llama-3.3-70b-versatile","name":"LLaMA 3.3 70B Versatile","description":"High-throughput, low-latency Groq model"}]}]'
